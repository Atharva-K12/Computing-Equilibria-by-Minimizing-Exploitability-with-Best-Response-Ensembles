import torch
import numpy as np
from scipy.spatial.distance import pdist, squareform


class CircleGame(torch.nn.Module):
    def __init__(self, n_players):
        super().__init__()
        self.n_players = n_players
        self.action_dim = 1
        self.action_space = torch.linspace(-np.pi, np.pi, 100)
        self.register_parameter('x', torch.nn.Parameter(torch.randn(n_players, 2)))
        self.register_parameter('log_s', torch.nn.Parameter(torch.randn(n_players)))
        
    def get_strategy(self):
        mus = torch.atan2(self.x[:, 1], self.x[:, 0])
        sigmas = torch.exp(self.log_s)
        strategies = torch.zeros(self.n_players, self.action_dim)
        for i in range(self.n_players):
            strategies[i] = torch.distributions.von_mises.VonMises(mus[i], sigmas[i]).sample()
        return strategies
        
    # def pairwise_distances(self, actions):
    #     diffs = actions.unsqueeze(0) - actions.unsqueeze(1)
    #     return torch.min(torch.abs(diffs), 2 * np.pi - torch.abs(diffs))

    def dist(self, a, b):
        diff = torch.clamp(torch.abs(a-b), 0, np.pi)/2
        return 2*torch.sin(diff)

        
    def forward(self, actions,i):
        # dists = self.pairwise_distances(actions)
        # rewards = -dists[:, :-1] + dists[:, -1:]
        rewards = self.dist(actions[i],actions[(i+1)%self.n_players])
        return rewards

    def init_actions(self, n_ensembles):
        actions = torch.zeros((n_ensembles, self.n_players, self.action_dim))
        for i in range(n_ensembles):
            actions[i] = self.get_strategy()
        return actions


def mix(strategy, epsilon):
    return (1 - epsilon) * strategy.max() + epsilon * strategy.sum()

def loss(expected_rewards, last_reward):
    loss_val = expected_rewards - last_reward

def concater(strategies, action_samples,i,j):
    return torch.cat((strategies[:i], action_samples[j][i].unsqueeze(0),strategies[i+1:]),dim=0)

    
def train(game, strategies,  n_iter=1000, lr=1e-3, eps=1e-3, n_ensembles=10):
    action_samples = game.init_actions(n_ensembles)
    print("action_samples shape: ", action_samples.shape)
    optimizer_strat = torch.optim.SGD([strategies], lr=lr)
    optimizer_action = torch.optim.SGD([action_samples], lr=lr)
    iter_exploitabilities = []
    for _ in range(n_iter):
        optimizer_action.zero_grad()
        optimizer_strat.zero_grad()
        reward_strategy = torch.zeros(game.n_players, requires_grad=True)
        mix_strategy = torch.zeros(game.n_players, requires_grad=True)
        max_strategy = torch.zeros(game.n_players, requires_grad=True)
        for i in range(game.n_players):
            ensemble_reward = torch.zeros(n_ensembles)
            reward_strategy[i] = game.forward(strategies,i)
            for j in range(n_ensembles):
                tempTensor = concater(strategies.detach(),action_samples,i,j)
                print("tempTensor shape: ", tempTensor.shape)
                ensemble_reward[j] = game.forward(tempTensor,i)
            max_strategy[i] = torch.max(ensemble_reward.detach())
            mix_strategy[i] = mix(ensemble_reward, eps)
        loss_max = torch.sum(max_strategy - reward_strategy)
        loss_mix = torch.sum(mix_strategy - reward_strategy.detach())
        loss_max.backward()
        loss_mix.backward()
        optimizer_strat.step()
        optimizer_action.step()
        iter_exploitabilities.append([loss_max.item(),loss_mix.item()])
        if iter_exploitabilities[-1][0] < 1e-10:
            break
        print("Exploitability: ", iter_exploitabilities[-1])
    return strategies, iter_exploitabilities




       
game = CircleGame(n_players=2)
strategies = game.get_strategy()
print("Strategies: ")
print(strategies)
strategies, exploitabilities = train(game, strategies, n_iter=10, lr=0.1, eps=0.5)
print("Strategies: ")
print(strategies)
print(exploitabilities)
# plot exploitabilities which is a list of tensor
import matplotlib.pyplot as plt
plt.plot(exploitabilities)
plt.show()

# exp_list = []
# for i in range(1):
#     strategies = best_response_ensemble(game, strategies, n_samples=3)
#     exp = exploitability(game, strategies)
#     print("strategies: ")
#     print(strategies)
#     exp_list.append(exp)
#     if i % 1 == 0:
#         print(f'Iteration {i}, exploitability: {exp}')


# plot exploitability
# import matplotlib.pyplot as plt
# plt.plot(exp_list)
# plt.show()
