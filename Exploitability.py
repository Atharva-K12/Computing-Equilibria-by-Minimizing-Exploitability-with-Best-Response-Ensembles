# import numpy as np
# import matplotlib.pyplot as plt

# # Define the matching pennies game
# X = np.array([[-1, 1], [1, -1]])  # Player 1's strategy set
# Y = np.array([[-1, 1], [1, -1]])  # Player 2's strategy set

# # Define the loss function
# def f(x, y):
#     return np.sum(X * np.outer(x, y))

# # Define the exploitability descent with best-response ensembles (BRE) method
# def BRE():
#     epsilon = 0.5
#     J = 3  # Ensemble size
#     x = np.zeros(X.shape[1])  # Player 1's initial strategy
#     y = np.zeros((Y.shape[0], J, Y.shape[1]))  # Player 2's initial ensemble of strategies
#     for i in range(Y.shape[0]):
#         for j in range(J):
#             y[i][j] = np.random.uniform(-1, 1, Y.shape[1])  # Initialize each ensemble element randomly
#     lr = 0.1  # Learning rate
#     for t in range(1000):
#         x_prev = np.copy(x)
#         y_prev = np.copy(y)
#         # Update player 1's strategy
#         grad_x = np.zeros(X.shape[1])
#         for j in range(J):
#             grad_x += (1 - epsilon) * (y[:, j] * np.sum(X, axis=1)).sum(axis=0)
#         print(y_prev)
#         print()
#         print(x_prev)
#         print()
#         print(np.sum(X * x_prev[:, None, None], axis=1))
#         grad_x += epsilon * np.sum((y_prev * np.sum(X * x_prev[:, None, None], axis=1)).sum(axis=0), axis=0)
#         x -= lr * grad_x
#         x = np.clip(x, -1, 1)
#         # Update player 2's ensemble of strategies
#         grad_y = np.zeros((Y.shape[0], J, Y.shape[1]))
#         for i in range(Y.shape[0]):
#             for j in range(J):
#                 grad_y[i][j] = (1 - epsilon) * (x * np.sum(Y, axis=1)[i])
#         grad_y += epsilon * (y_prev * np.sum(X * x_prev[:, None, None], axis=1)).sum(axis=0)
#         y -= lr * grad_y
#         y = np.clip(y, -1, 1)
#         # Print the loss
#         print(f(x, y))
#         # Plot the loss graph
#         plt.plot(t, f(x, y), 'ro')
#     plt.xlabel('Iteration')
#     plt.ylabel('Loss')
#     plt.show()

# # Run the BRE method
# BRE()

import numpy as np
import matplotlib.pyplot as plt

# Define the matching pennies game
X = np.array([-1, 1])
Y = np.array([-1, 1])
def f(x, y):
    print("x = ", x)
    print("y = ", y)
    print("result= ", np.sum(X * np.outer(x, y)))
    return np.sum(X * np.outer(x, y))

# Define the best-response function for player 2
def best_response_player2(x):
    br_y = np.argmax([f(x, y) for y in Y])
    print(br_y)
    return Y[br_y]

# Initialize the ensemble of responses for player 2
J = 5
y = np.random.uniform(-1, 1, (J, len(Y)))

# Define the rank-based weighting function
def mix(a, epsilon=0.5):
    a_sorted = np.argsort(a)[::-1] # sort in descending order
    weights = np.zeros_like(a)
    weights[a_sorted[0]] = 1 - epsilon
    weights[a_sorted[1:]] = epsilon / (len(a) - 1)
    return weights

# Initialize player 1's strategy
x = np.random.uniform(-1, 1, len(X))

# Set up the training loop
epochs = 5
lr = 0.1
for epoch in range(epochs):
    # Compute the gradient for player 1's strategy
    print("x = ", x)
    print("y = ", y	)
    br_y = best_response_player2(x)
    print("best response y= ", br_y)
    grad_x = -np.array([f(x, br_y)*yj[np.argmax([f(x, yj) for yj in y])] for yj in y]).mean(axis=0)
    # Update player 1's strategy
    x += lr*grad_x
    # Compute the gradient for player 2's ensemble of responses
    grad_y = np.array([mix([f(x, yj) for yj in y], epsilon=0.5)*np.array([f(x, yj)*int(np.argmax([f(x, yj) for yj in y]) == j) for yj in y]).mean(axis=0) for j in range(len(Y))]).mean(axis=0)
    # Update player 2's ensemble of responses
    y += lr*grad_y.reshape(-1, 1)*(Y.reshape(1, -1) - y)
    # Print the loss
    print("Updated x = ", x)
    print("Updated y = ", y)
    print("loss: ",f(x, br_y))
    #plot the loss graph
    plt.plot(epoch, f(x, br_y), 'ro')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.show()
